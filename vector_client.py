"""
–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
"""
import logging
import asyncio
from typing import List, Dict, Optional, Tuple
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import numpy as np

from config import (
    VECTOR_DB_PATH, 
    EMBEDDING_MODEL, 
    VECTOR_SEARCH_LIMIT, 
    VECTOR_SIMILARITY_THRESHOLD
)

logger = logging.getLogger(__name__)


class VectorClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        self.client = None
        self.collection = None
        self.embedding_model = None
        self.initialized = False
    
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ChromaDB
            self.client = chromadb.PersistentClient(
                path=VECTOR_DB_PATH,
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            
            # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
            self.collection = self.client.get_or_create_collection(
                name="user_memories",
                metadata={"hnsw:space": "cosine"}
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            self.embedding_model = SentenceTransformer(EMBEDDING_MODEL)
            
            self.initialized = True
            logger.info("‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö ChromaDB –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!")
            logger.info(f"üìÅ –ü—É—Ç—å –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î: {VECTOR_DB_PATH}")
            logger.info(f"ü§ñ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {EMBEDDING_MODEL}")
            logger.info(f"üìä –ö–æ–ª–ª–µ–∫—Ü–∏—è: {self.collection.name}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã: {e}")
            raise
    
    async def add_memory(
        self, 
        memory_id: str, 
        user_id: int, 
        content: str, 
        memory_type: str,
        importance: str,
        tags: List[str] = None,
        metadata: Dict = None
    ) -> bool:
        """–î–æ–±–∞–≤–∏—Ç—å –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É"""
        try:
            if not self.initialized:
                await self.initialize()
            
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            embedding = self.embedding_model.encode(content).tolist()
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ —É–¥–∞–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è None,
            # —Ç–∞–∫ –∫–∞–∫ ChromaDB –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç None –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            base_metadata = {
                "user_id": user_id,
                "memory_type": memory_type,
                "importance": importance,
                "tags": ",".join(tags) if tags else ""
            }
            extra_metadata = {
                key: value
                for key, value in (metadata or {}).items()
                if value is not None
            }
            memory_metadata = {
                key: value
                for key, value in {**base_metadata, **extra_metadata}.items()
                if value is not None
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
            self.collection.add(
                ids=[memory_id],
                embeddings=[embedding],
                documents=[content],
                metadatas=[memory_metadata]
            )
            
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ {memory_id} –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É: {e}")
            return False
    
    async def search_similar_memories(
        self, 
        user_id: int, 
        query: str, 
        memory_types: List[str] = None,
        limit: int = None
    ) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        try:
            if not self.initialized:
                await self.initialize()
            
            if limit is None:
                limit = VECTOR_SEARCH_LIMIT
            
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = self.embedding_model.encode(query).tolist()
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏–ª—å—Ç—Ä
            where_filter = {"user_id": user_id}
            if memory_types:
                where_filter["memory_type"] = {"$in": memory_types}
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=limit,
                where=where_filter,
                include=["documents", "metadatas", "distances"]
            )
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            similar_memories = []
            if results["documents"] and results["documents"][0]:
                for i, (doc, metadata, distance) in enumerate(zip(
                    results["documents"][0],
                    results["metadatas"][0],
                    results["distances"][0]
                )):
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ —Å—Ö–æ–∂–µ—Å—Ç—å (1 - distance)
                    similarity = 1 - distance
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É —Å—Ö–æ–∂–µ—Å—Ç–∏
                    if similarity >= VECTOR_SIMILARITY_THRESHOLD:
                        similar_memories.append({
                            "content": doc,
                            "metadata": metadata,
                            "similarity": similarity,
                            "distance": distance
                        })
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(similar_memories)} –ø–æ—Ö–æ–∂–∏—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query[:50]}")
            return similar_memories
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {e}")
            return []
    
    async def get_user_memories_by_type(
        self, 
        user_id: int, 
        memory_type: str,
        limit: int = None
    ) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ —Ç–∏–ø—É"""
        try:
            if not self.initialized:
                await self.initialize()
            
            if limit is None:
                limit = VECTOR_SEARCH_LIMIT
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞
            results = self.collection.get(
                where={
                    "user_id": user_id,
                    "memory_type": memory_type
                },
                limit=limit,
                include=["documents", "metadatas"]
            )
            
            memories = []
            if results["documents"]:
                for doc, metadata in zip(results["documents"], results["metadatas"]):
                    memories.append({
                        "content": doc,
                        "metadata": metadata
                    })
            
            logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(memories)} –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π —Ç–∏–ø–∞ {memory_type} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return memories
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –ø–æ —Ç–∏–ø—É: {e}")
            return []
    
    async def get_important_memories(
        self, 
        user_id: int, 
        importance_levels: List[str] = None,
        limit: int = None
    ) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤–∞–∂–Ω—ã–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            if not self.initialized:
                await self.initialize()
            
            if limit is None:
                limit = VECTOR_SEARCH_LIMIT
            
            if importance_levels is None:
                importance_levels = ["high", "critical"]
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω—ã–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è
            results = self.collection.get(
                where={
                    "user_id": user_id,
                    "importance": {"$in": importance_levels}
                },
                limit=limit,
                include=["documents", "metadatas"]
            )
            
            memories = []
            if results["documents"]:
                for doc, metadata in zip(results["documents"], results["metadatas"]):
                    memories.append({
                        "content": doc,
                        "metadata": metadata
                    })
            
            logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(memories)} –≤–∞–∂–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return memories
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∞–∂–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {e}")
            return []
    
    async def delete_memory(self, memory_id: str) -> bool:
        """–£–¥–∞–ª–∏—Ç—å –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã"""
        try:
            if not self.initialized:
                await self.initialize()
            
            self.collection.delete(ids=[memory_id])
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ {memory_id} –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è: {e}")
            return False
    
    async def update_memory(
        self, 
        memory_id: str, 
        content: str = None,
        metadata: Dict = None
    ) -> bool:
        """–û–±–Ω–æ–≤–∏—Ç—å –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ"""
        try:
            if not self.initialized:
                await self.initialize()
            
            update_data = {}
            
            if content:
                # –û–±–Ω–æ–≤–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                embedding = self.embedding_model.encode(content).tolist()
                update_data["embeddings"] = [embedding]
                update_data["documents"] = [content]
            
            if metadata:
                update_data["metadatas"] = [metadata]
            
            if update_data:
                self.collection.update(
                    ids=[memory_id],
                    **update_data
                )
                logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ {memory_id} –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ")
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è: {e}")
            return False
    
    async def get_collection_stats(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            if not self.initialized:
                await self.initialize()
            
            count = self.collection.count()
            
            stats = {
                "total_memories": count,
                "collection_name": self.collection.name,
                "embedding_model": EMBEDDING_MODEL
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
vector_client = VectorClient()
